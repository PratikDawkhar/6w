Importre
Fromnltk.tokenizeimportsent_tokenize
#Textparagraph
Text=“So,keepworking.Keepstriving.Nevergiveup.Falldownseventimes,getupeight.Easeisagreaterthreattoprogressthanhardship.Easeisagreaterthreattoprogressthanhardship.So,keepmoving,keepgrowing,keeplearning.Seeyouatwork.”
#Removespecialcharactersanddigits
Text=re.sub(‘[^A-Za-z]+’,‘‘,text)
#Tokenizethesentences
Sentences=sent_tokenize(text)
#Calculatethescoreofeachsentencebasedonthenumberofwords#Thesentenceswithmorewordswillhaveahigherscore
Scores={}
Forsentenceinsentences:
Words=sentence.split()
Score=len(words)
Scores[sentence]=score
#Sortthesentencesbasedontheirscores
Sorted_sentences=sorted(scores.items(),key=lambdax:x[1],reverse=True)#Extractthetop2sentenceswiththehighestscoresasthesummarySummary_sentences=[sentence[0]forsentenceinsorted_sentences[:2]]Summary=““.join(summary_sentences)
#Printthesummary
Print(summary)